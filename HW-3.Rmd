---
title: "MATH 216 Homework 3"
author: "Alison Cook"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(Quandl))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(knitr))
```


## Admistrative:

Please indicate

* Who you collaborated with: Jacob Dixon, Carter Merenstein, Andrew Holtz
* Roughly how much time you spent on this HW: 13 Hours
I have now spent over 45 minutes just trying to get this to knit
* What gave you the most trouble: Interpreting questions, trying to get data in the right format, solving tiny problems and misconceptions. 
* Any comments you have: Even though this was pared down, it was still a lot of troubleshooting!


## Data

* You must first copy the file `profiles.csv` from `HW-2` to the `data` folder
in the `HW-3` directory
* We also consider all 222,540 songs played in the Reed College pool hall
jukebox from Nov 30, 2003 to Jan 22, 2009 (included in `HW-3` folder). 

```{r, echo=FALSE, cache=TRUE}
# DO NOT EDIT THIS SECTION!
profiles <- read.csv("data/profiles.csv", header=TRUE) %>% 
  tbl_df()
jukebox <- read.csv("data/jukebox.csv", header=TRUE) %>% 
  tbl_df()
```





## Question 1:

For this question we will be picking up from where we left off in HW-2,
specifically the OkCupid dataset.


### a)

Using your exploratory data analysis from HW-2, fit a logistic regression to predict individual's gender and interpret the results for one continuous variable (if you used one) and one categorical variable of your choice.

```{r, echo=FALSE, fig.width=12, fig.height=6}
profiles <- filter(profiles, sex != "")
essays <- select(profiles, contains("essay"))
profiles <- select(profiles, -contains("essay"))
profiles <- mutate(profiles, is_female = ifelse(sex=="f", 1, 0))

##from previous assignment

#height and makeup!
profiles <- mutate(profiles, num_height = as.numeric(as.character(height)))

ggplot(data=profiles, aes(x=num_height, y=is_female)) +
  geom_jitter(height=0.2, alpha = 0.1) +
  xlim(c(50, 80)) + 
  labs(title = "Range of Heights on Bay Area OKCupid Profiles", x = "Age", y = "Is Female")

find.query <- function(char.vector, query){
  which.has.query <- grep(query, char.vector, ignore.case = TRUE)
  length(which.has.query) != 0
}
profile.has.query <- function(data.frame, query){
  query <- tolower(query)
  has.query <- apply(data.frame, 1, find.query, query=query)
  return(has.query)
}

profiles$has_makeup <- profile.has.query(data.frame = essays, query = "makeup")
group_by(profiles, has_makeup) %>% 
  summarise(prop_female=mean(is_female)) %>% kable(., digits = 3)

#fit model
model_1 <- glm(is_female ~ has_makeup + num_height, data=profiles, family=binomial, na.action = na.exclude)
l <- summary(model_1)
kable(l$coef, digits = 3)
```

Here, I'm using analysis of heights and use of the word "makeup" to fit a model to predict gender of Bay Area OK Cupid users. The jitter plot shows the range of heights of OK Cupid users organized by gender, where 1 corresponds to female and 0 corresponds to male. The table of "has makeup" organized by True/False shows the proportion of each response that is female (e.g. 75% of those who used the word "makeup" in their profile essays were female). A logistic regresion of these variables indicates that the odds of women using "makeup" in their profile is exp(1.68) for each increase in one and the odds that a user is female is exp(-0.64) for each increase of one in height. 



### b)

Plot a histogram of the fitted probabilities $\widehat{p}_i$ for all users $i=1,
\ldots, n=59946$ in your dataset.

```{r, echo=FALSE, fig.width=12, fig.height=6}
p_hat <- fitted(model_1)

ggplot(data = NULL, aes(x = p_hat)) +
  geom_histogram(binwidth = 0.2, col="blue", 
                 fill="blue", 
                 alpha = .2) +
  geom_vline(xintercept = 0.5, col = "red") +
  labs(title = "Histogram of Fitted Probabilities", x = "P hat", 
       y = "Count of OK Cupid Users")

```

This histogram shows the fitted probability of each user's gender based on the model above. The red line represents p = 0.5, exactly in between 0 (male) and 1 (female)--users close to this line are not well predicted by the model, while users at 0 and 1 are almost certainly male or female as predicted by the model.

### c)

Use a *decision threshold* of $p^*=0.5$ to make an explicit prediction for each
user $i$'s sex and save this in a variable `predicted_sex`. In other words, for user $i$

* If $\widehat{p}_i > p^*$, set `predicted_sex = 1` i.e. they are female
* If $\widehat{p}_i < p^*$, set `predicted_sex = 0` i.e. they are male

Display a 2 x 2 contigency table of `sex` and `predicted_sex` i.e. compare the 
predicted sex to the actual sex of all users. The sum of all the elements in
your table should be $n=59946$. Comment on how well our predictions fared.

```{r, echo=FALSE, fig.width=12, fig.height=6}
fit_pred <- ifelse(p_hat >= 0.5, 1, 0)

profiles$pred_female <- fit_pred

obs <- profiles  %>% group_by(is_female)  %>% tally()
pred <- profiles  %>% group_by(pred_female)  %>% tally()

contingency <- matrix(nrow = 2, ncol = 2)
colnames(contingency) <- c("Actual", "Predicted")
rownames(contingency) <- c("Male", "Female")

contingency[1,1] <- obs[1,2][[1]]
contingency[2,1] <- obs[2,2][[1]]
#contingency[4,1] <- contingency[1,1] + contingency[2,1]

contingency[1,2] <- pred[1,2][[1]]
contingency[2,2] <- pred[2,2][[1]]
#contingency[3,2] <- pred[3,2][[1]]
#contingency[4,2] <- contingency[1,2] + contingency[2,2] + contingency[3,2]

kable(as.data.frame(contingency))
```

This table shows the actual versus predicted counts of males and females based on the model above. A threshold probability of 0.5 and above was used to predict female users. There are 3 users that the model failed to predict due to missing height or essay responses (or both). It is possible that the reason the counts sum to 59943 instead of 59946 is because I eliminated users that didn't report gender from being included in the model in the first place. This model does a resonably good job predicting--949 users were predicted incorrectly. Overall, 2% of males and 4% of females were assigned to incorrect genders. 

### d)

Say we wanted to have a **false positive rate** of about 20%, i.e. of the people
we predicted to be female, we want to be wrong no more than 20% of the time. What
decision threshold $p^*$ should we use?

```{r, echo=FALSE, fig.width=12, fig.height=6}

```





## Question 2:

Using the jukebox data, plot a time series of the number of songs played each
week over the entire time period. i.e.

* On the x-axis present actual dates (not something like Week 93, which doesn't 
mean anything to most people).
* On the y-axis present the total number of songs.

What seasonal (i.e. cyclical) patterns do you observe?

```{r, echo=FALSE, fig.width=12, fig.height=6}
jukebox <- jukebox %>% mutate(Date_format = parse_date_time(date_time, "%b %d %H%M%S %y"))
jukebox <- jukebox %>% separate(Date_format, c("Date", "Time"), sep = " ")
jukebox <- jukebox %>% mutate(week = week(Date))
jukebox <- jukebox %>% mutate(year = year(Date))
songs_per_week <- jukebox  %>% group_by(year, week)  %>% tally() 
songs_per_week$date <- as.Date(paste(songs_per_week$year, 
                                     songs_per_week$week, 1, sep="-"), "%Y-%U-%u")

ggplot(data = songs_per_week, aes(x = date, y = n)) +
  geom_area() +
  labs(title = "Songs Played Per Week", x = "Date",
       y = "Number of Songs")

#seasonal patterns?
songs_per_week <- songs_per_week %>% mutate(month = month(date)) %>% select(month, n)

#tell R which months are in which seasons
winter <- c(12, 1, 2)
spring <- c(3, 4, 5)
summer <- c(6, 7, 8)
autumn <- c(9, 10, 11)

songs_by_season <- songs_per_week %>% 
  mutate(season = ifelse(month %in% winter, 'winter', 
                         ifelse(month %in% spring, 'spring', 
                                ifelse(month %in% summer, 'summer', 
                                       ifelse(month %in% autumn, 'autumn', NA)))))


ggplot(data = songs_by_season, aes(x = season, y = n)) +
  geom_boxplot() +
  labs(title = "Songs Played by Season", x= "Season",
       y = "Number of Songs")

#highly variable in winter due to break?
```

A chart of number of songs per week from 2004-2009 shows distinct periodicity between seasons. Number of songs per week drops continuously until toward the middle of the year and then spikes back up at the end. Looking at a boxplot of seasons, we can see that the most songs per week are played in the autumn with little variability (perhaps students are excited school is starting back up). During the summer, songs per week dips to its lowest point, likely because fewer regular students are on campus. Finally, winter sees the most spread in number of songs played per week. This is most likley due to the large winter break where few songs are played juxtaposed with the end and beginning of semesters. 



## Question 3:

Using the jukebox data, what are the top 10 artists played during the "graveyard
shift" during the academic year? Define

* the "graveyard shift" as midnight to 8am
* the academic year as September through May (inclusive)

```{r, echo=FALSE, fig.width=12, fig.height=6}
jukebox <- jukebox %>% mutate(month = month(Date))

academic <- c(9, 10, 11, 12, 1, 2, 3, 4, 5)

academic_songs <- jukebox %>% 
  mutate(academic = ifelse(month %in% academic, 'academic', 'break')) %>% 
  filter(academic == "academic")

academic_songs <- academic_songs %>% filter(Time > "00:00:00", Time < "08:00:00")

academic_songs %>% group_by(artist) %>% 
  tally() %>% arrange(desc(n)) %>% slice(1:10) %>% kable()
```

This table shows the top ten artists played during the "graveyard shift" of the academic year during 2004 through 2009. It's nice to see some classics in here.



## Question 4:

We want to compare the volatility of 

* bitcoin prices
* gold prices

Let our measure of volatility be the relative change from day-to-day in price. 
Let the reference currency be US dollars. Analyze these results and provide
insight to a foreign currency exchanger.

```{r, echo=FALSE, fig.width=12, fig.height=6}
bitcoin <- Quandl("BAVERAGE/USD") %>% tbl_df()
gold <- Quandl("WGC/GOLD_DAILY_USD") %>% tbl_df()
bitcoin <- rename(bitcoin, Avg = `24h Average`, Total.Volume = `Total Volume`)

currency <- left_join(bitcoin, gold, by = "Date")

##make this prettier
ggplot(data = currency, aes(x = Date)) +
  geom_line(aes(x = Date, y = Avg), colour = "blue") +
  geom_line(aes(x = Date, y = Value), colour = "green") +
  labs(title = "Variation in Average Currency Prices", x = "Date",
       y = "Average Price for Day (USD)")

bitcoin_diff <- as.data.frame(diff(currency$Avg))
bitcoin_diff <- mutate(bitcoin_diff, Date = currency$Date[2:2076])
bitcoin_diff <- rename(bitcoin_diff, Diff = `diff(currency$Avg)`)

gold_diff <- as.data.frame(diff(currency$Value))
gold_diff <- mutate(gold_diff, Date = currency$Date[2:2076])
gold_diff <- rename(gold_diff, Diff = `diff(currency$Value)`)

currency_diff <- left_join(bitcoin_diff, gold_diff, by = "Date")
currency_diff <- rename(currency_diff, bitcoin_diff = `Diff.x`, gold_diff = `Diff.y`)
currency_diff <- currency_diff[,c(2,1,3)]
currency_diff <- gather(currency_diff, "currency", "diff", 2:3)

ggplot(data = bitcoin_diff, aes(x = Diff)) +
  geom_histogram() +
  xlim(-200,200) +
  labs(title = "Daily Variation in Bitcoin Prices", x = "Daily Difference in Price of Gold",
       y = "Frequency")

ggplot(data = gold_diff, aes(x = Diff)) +
  geom_histogram() +
  xlim(-200,200)+
  labs(title = "Daily Variation in Gold Prices", x = "Daily Difference in Price of Gold",
       y = "Frequency")

ggplot(data = currency_diff, aes(x = Date, y = diff, fill = currency)) +
  geom_bar(stat = "identity", position = "dodge") +
  ylim(-100,100) +
  labs(title = "Daily Variation in Gold and Bitcoin Prices", x = "Date",
       y = "Difference in USD Compared to Previous Day")

```

Generally, gold prices are higher and have less fluctuation than bitcoin prices. According to the first graph, which shows general variation in prices, gold has a higher value in USD, but has been steadily decreasing in value since 2013 while bitcoin spiked in value right before 2014, and has varied significantly since. When daily differences are plotted on a histogram, variation in gold prices shows a more uniform distribution. However, time span is taken into account, bitcoins have more variability day to day, particularly after 2014. Gold is a more stable investment than are bitcoins, however, bitcoins holds the potential for a higher payout. 






## Question 5:

Using the data loaded from Quandl below, plot a time series using `geom_line()`
comparing cheese and milk production in the US from 1930 to today. Comment on this.

* Cheese [page](https://www.quandl.com/data/USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB-Cheese-Production-Measured-In-Lb)
* Milk [page](https://www.quandl.com/data/USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB-Milk-Production-Measured-In-Lb)

```{r, echo=FALSE, fig.width=12, fig.height=6}
cheese <- Quandl("USDANASS/NASS_CHEESEPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
milk <-  Quandl("USDANASS/NASS_MILKPRODUCTIONMEASUREDINLB") %>% 
  tbl_df()
```

